Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job          count
---------  -------
load_data        1
total            1

Select jobs to execute...

[Sun Jul 14 21:40:35 2024]
rule load_data:
    input: data/rse.xlsx
    output: data/raw_data.csv
    jobid: 0
    reason: Missing output files: data/raw_data.csv
    resources: tmpdir=/tmp

[Sun Jul 14 21:40:35 2024]
Error in rule load_data:
    jobid: 0
    input: data/rse.xlsx
    output: data/raw_data.csv

RuleException:
WorkflowError in file /home/murtaza/research-software-engineering-project-2/Snakefile, line 19:
Failed to open source file /home/murtaza/research-software-engineering-project-2/load_data.py
FileNotFoundError: [Errno 2] No such file or directory: '/home/murtaza/research-software-engineering-project-2/load_data.py'
  File "/home/murtaza/research-software-engineering-project-2/Snakefile", line 19, in __rule_load_data
  File "/usr/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-07-14T214035.565191.snakemake.log
