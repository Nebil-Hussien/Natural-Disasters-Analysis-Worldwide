Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job           count
----------  -------
clean_data        1
total             1

Select jobs to execute...

[Sun Jul 14 22:13:21 2024]
rule clean_data:
    input: data/rse.xlsx
    output: results/clea_data.xlsx
    jobid: 0
    reason: Missing output files: results/clea_data.xlsx
    resources: tmpdir=/tmp

[Sun Jul 14 22:13:21 2024]
Error in rule clean_data:
    jobid: 0
    input: data/rse.xlsx
    output: results/clea_data.xlsx

RuleException:
NameError in file /home/murtaza/research-software-engineering-project-2/Snakefile, line 25:
The name 'input' is unknown in this context. Please make sure that you defined that variable. Also note that braces not used for variable access have to be escaped by repeating them, i.e. {{print $1}}
  File "/home/murtaza/research-software-engineering-project-2/Snakefile", line 25, in __rule_clean_data
  File "/usr/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-07-14T221321.496471.snakemake.log
