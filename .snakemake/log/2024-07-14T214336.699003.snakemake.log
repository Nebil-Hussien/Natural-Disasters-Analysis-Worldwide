Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job          count
---------  -------
load_data        1
total            1

Select jobs to execute...

[Sun Jul 14 21:43:36 2024]
rule load_data:
    input: data/rse.xlsx
    output: data/raw_data.csv
    jobid: 0
    reason: Missing output files: data/raw_data.csv
    resources: tmpdir=/tmp

[Sun Jul 14 21:43:37 2024]
Error in rule load_data:
    jobid: 0
    input: data/rse.xlsx
    output: data/raw_data.csv

RuleException:
CalledProcessError in file /home/murtaza/research-software-engineering-project-2/Snakefile, line 19:
Command 'set -euo pipefail;  /home/murtaza/research-software-engineering-project-2/snakemake-env/bin/python3 /home/murtaza/research-software-engineering-project-2/.snakemake/scripts/tmp612pfmi7.load_data.py' returned non-zero exit status 2.
  File "/home/murtaza/research-software-engineering-project-2/Snakefile", line 19, in __rule_load_data
  File "/usr/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-07-14T214336.699003.snakemake.log
